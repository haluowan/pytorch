{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm for parts of speech prediction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haluowan/pytorch/blob/master/lstm_for_parts_of_speech_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf6aG0uS9GZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4oNiT_BUGjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load training data\n",
        "training_data = [('The dog ate the apple'.split(),\n",
        "                ['DET','NN','V','DET','NN']),\n",
        "               ('Everybody read that book'.split(),\n",
        "               ['NN','V','DET','NN'])]\n",
        "# ecoding words and tags\n",
        "word_to_idx = {}\n",
        "tag_to_idx = {}\n",
        "for context,tag in training_data:\n",
        "    for word in context:\n",
        "        if word.lower() not in word_to_idx:\n",
        "            word_to_idx[word.lower()] = len(word_to_idx)\n",
        "    for label in tag:\n",
        "        if label.lower() not in tag_to_idx:\n",
        "            tag_to_idx[label.lower()] = len(tag_to_idx)\n",
        "\n",
        "# print(word_to_idx)\n",
        "# print(tag_to_idx)\n",
        "\n",
        "# encoding alphabet \n",
        "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
        "char_to_idx = {}\n",
        "for i in range(len(alphabet)):\n",
        "    char_to_idx[alphabet[i]] = i"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FpFdxFKB8lC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_sequence(x,dic):\n",
        "    \"\"\"\n",
        "    character code\n",
        "    \"\"\"\n",
        "    idx = [dic[i.lower()] for i in x]\n",
        "    idx = torch.LongTensor(idx)\n",
        "    return idx\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COsQ-R1cCy57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class char_lstm(nn.Module):\n",
        "    \"\"\"\n",
        "     lstm for single character\n",
        "    \"\"\"\n",
        "    def __init__(self,n_char,char_dim,char_hidden):\n",
        "        super(char_lstm,self).__init__()\n",
        "        \n",
        "        self.char_embed = nn.Embedding(n_char,char_dim)\n",
        "        self.lstm = nn.LSTM(char_dim,char_hidden)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = self.char_embed(x)\n",
        "        out,_ = self.lstm(x)\n",
        "        # (batch,hidden)\n",
        "        return out[-1] \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-P1ILsqEax_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class tagger_lstm(nn.Module):\n",
        "    \"\"\"\n",
        "    lstm for part of speech\n",
        "    \"\"\"\n",
        "    def __init__(self,n_word,n_char,char_dim,word_dim,\n",
        "                 char_hidden,word_hidden,n_tag):\n",
        "        super(tagger_lstm,self).__init__()\n",
        "        \n",
        "        self.word_embed = nn.Embedding(n_word,word_dim)\n",
        "        self.char_lstm = char_lstm(n_char,char_dim,char_hidden)\n",
        "        self.word_lstm = nn.LSTM(word_dim + char_hidden,word_hidden)\n",
        "        self.classify = nn.Linear(word_hidden,n_tag)\n",
        "        \n",
        "    def forward(self,x,word):\n",
        "        char = []\n",
        "        for w in word:\n",
        "            char_list = make_sequence(w,char_to_idx)\n",
        "            char_list = char_list.unsqueeze(1) # (seq,batch,feature)\n",
        "            char_infor = self.char_lstm(char_list) #(batch,char_hidden)\n",
        "            \n",
        "            char.append(char_infor)\n",
        "        char = torch.stack(char,dim=0) # (seq,batch,feature)\n",
        "        \n",
        "        x = self.word_embed(x) # (batch,seq,word_dim)\n",
        "        x = x.permute(1,0,2) # rechange the sequence\n",
        "        x = torch.cat((x,char),dim=2)\n",
        "        x,_ = self.word_lstm(x)\n",
        "        \n",
        "        s,b,h = x.shape\n",
        "        x = x.view(-1,h) # reshape the linear layer\n",
        "        out = self.classify(x)\n",
        "        return out\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHL_uCyTUMRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = tagger_lstm(len(word_to_idx),len(char_to_idx),10,100,50,128,\n",
        "                  len(tag_to_idx))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(),lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CquHVAzgJwnC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "44e292ba-7391-4006-8603-a3c04fd149a5"
      },
      "source": [
        "for e in range(300):\n",
        "    train_loss = 0\n",
        "    for word,tag in training_data:\n",
        "        word_list = make_sequence(word,word_to_idx).unsqueeze(0)\n",
        "        tag = make_sequence(tag,tag_to_idx)\n",
        "    # forward    \n",
        "    out = net(word_list,word)\n",
        "    loss = criterion(out,tag)\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "if (e+1) %100 ==0:\n",
        "    print('Epoch:{},Loss:{:.5f}'.format(e+1,train_loss / len(training_data)))\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:300,Loss:0.49400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ikug34yILu4g",
        "colab_type": "code",
        "outputId": "aa60e1bc-1938-4e8e-f669-2466de608449",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "\n",
        "# show the prediction result\n",
        "net = net.eval()\n",
        "test_sent = 'Everybody ate the apple'\n",
        "test = make_sequence(test_sent.split(),word_to_idx).unsqueeze(0)\n",
        "out = net(test,test_sent.split())\n",
        "print('out=',out)\n",
        "print('tag_to_idx=',tag_to_idx)\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "out= tensor([[-0.2296,  0.0620,  0.0087],\n",
            "        [-0.1588,  0.0211,  0.0201],\n",
            "        [-0.1828, -0.0061, -0.0836],\n",
            "        [-0.0907,  0.0862,  0.0094]], grad_fn=<AddmmBackward>)\n",
            "tag_to_idx= {'det': 0, 'nn': 1, 'v': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PtTfUi0QXEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}